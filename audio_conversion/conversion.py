################################################################################
# Filename: conversion.py
# Purpose:  Perform audio processing and conversion tasks to MIDI.
# Author:   Livia Chandra
#
# Description:
# This file contains functions for audio processing tasks, including conversion
# of audio files to MIDI format. It includes helper functions for audio file
# conversion to wav file, frequency segmentation, and MIDI file generation.
#
# Usage (Optional):
# User can use the provided functions to convert audio files to MIDI format.
# Ensure that the required dependencies, such as pydub, librosa, numpy, scipy,
# and mido, are installed in user's Python environment.
#
# Notes:
# - This file supports audio files with extensions mp3, m4a, and wav.
# - Ensure that the audio files contain a single melody line for accurate
#   MIDI conversion.
# - The MIDI files generated by this file will contain MIDI note messages
#   corresponding to the detected pitch and rhythm of the input audio.
#
###############################################################################

import pydub
import librosa
import numpy as np
import scipy.signal as signal
import math
import mido
import os

audio_folder = "audio_sample"
midi_folder = "midi_output"


def audio_to_wav(audio_file):
    """
    Helper function to convert audio file into wav file for MIDI conversion.

    Args:
        audio_file (string): The path to obtain audio file.

    Returns:
        file_name (string): File name to name converted MIDI file.
        wav_file (string): The path to obtain audio file with wav extension.
    """

    # List of accepted audio file type
    available_extension = ["m4a", "mp3", "wav"]

    # Get the name and the extension type of the input audio file
    file_name, extension = audio_file.split(".")
    file_name = file_name.split("/")[-1]

    # Check the extension of the input audio file
    if extension not in available_extension:
        return None

    # Convert input audio file to wav file
    wav_file_path = os.path.join(audio_folder, file_name + ".wav")
    wav_file = pydub.AudioSegment.from_file(audio_file, extension).export(
        wav_file_path, format="wav"
    )

    return file_name, wav_file


def divide_audio_data(audio_data, sample_rate, tempo):
    """
    Helper function to divide array into segments with variable length based on BPM.

    Args:
        audio_data (ndarray): 1D array that contains audio signal information
        sample_rate (int): Number of samples per second (Hz) used when loading the
                           audio file.
        tempo (float64): Estimated tempo of the audio signal in beats per minute (BPM)

    Yields:
        ndarray: Segments of audio data with variable length based on the BPM.
    """

    # Calculate the duration of one beat in seconds
    beat_duration = 60 / tempo

    # Calculate the desired length of each segment based on the beat duration
    desired_len = int(sample_rate * beat_duration * 2)

    # Loop through the array and yield segments of the desired length
    for i in range(0, len(audio_data), desired_len):
        yield audio_data[i : i + desired_len]


def wav_to_midi(audio_file):
    """
    Convert audio file to MIDI format.

    Args:
        audio_file (str): The path to the audio file.

    Returns:
        str: The path to the generated MIDI file.
    """

    # Convert audio file into wav file
    file_name, wav_file = audio_to_wav(audio_file)

    if wav_file is None:
        return None

    # Load audio file using librosa
    audio_data, sample_rate = librosa.load(wav_file)

    # Set min and max frequencies for pitch detection
    fmin = librosa.note_to_hz("C1")
    fmax = librosa.note_to_hz("C8")

    # Perform pitch detection to identify dominant pitch
    pitch = librosa.yin(y=audio_data, sr=sample_rate, fmin=fmin, fmax=fmax)

    # Find the most frequent pitch
    dominant_pitch = np.argmax(pitch)

    # Determine key signature by mapping MIDI note number
    key_map = {
        0: "C",
        1: "C#",
        2: "D",
        3: "D#",
        4: "E",
        5: "F",
        6: "F#",
        7: "G",
        8: "G#",
        9: "A",
        10: "A#",
        11: "B",
    }
    key_signature = key_map[int(dominant_pitch) % 12]

    # Obtain BPM
    tempo, beat_frames = librosa.beat.beat_track(y=audio_data, sr=sample_rate)

    # Obtain time
    beat_times = librosa.frames_to_time(beat_frames, sr=sample_rate)

    # Divide audio into segments with variable length based on BPM
    trimmed_frequency = list(divide_audio_data(audio_data, sample_rate, tempo))

    # STFT Parameters
    window_size = 256  # Window size
    hop_length = 64  # Hop length

    # Analyze frequency for each time frame
    frequency_list = []

    # Compute STFT for each segment
    for frequency in trimmed_frequency:

        # Adjust nperseg and noverlap based on the length of the segment
        nperseg = min(len(frequency), window_size)
        noverlap = nperseg - hop_length
        _, _, stft = signal.stft(
            frequency, fs=sample_rate, nperseg=nperseg, noverlap=noverlap
        )

        # Sum across time axis to get magnitude spectrum
        magnitude_spectrum = np.abs(stft).mean(axis=1)

        # Convert to frequency domain
        frequency_bins = np.fft.fftfreq(len(magnitude_spectrum)) * sample_rate

        # Weighted median frequency
        median_freq_index = np.argmax(
            np.cumsum(magnitude_spectrum) >= np.sum(magnitude_spectrum) / 2
        )
        median_freq = frequency_bins[median_freq_index]

        frequency_list.append(median_freq)

    # Filter out invalid frequencies
    filtered_frequency_list = [freq for freq in frequency_list if freq > 0]

    # Set the velocity to determine the volume of output midi file
    velocity = 127

    # Calculate MIDI notes
    midi_note = [
        (int(12 * math.log(freq / 440.0) / math.log(2)) + 69)
        for freq in filtered_frequency_list
    ]

    # Create a new MIDI file and track
    midi = mido.MidiFile()
    track = mido.MidiTrack()
    midi.tracks.append(track)

    # Set the key signature meta message
    key_sig_message = mido.MetaMessage("key_signature", key=key_signature, time=0)
    track.append(key_sig_message)

    # Calculate MIDI time based on tempo
    midi_time = [
        (beat_times[i] - beat_times[i - 1]) * 60 / tempo
        for i in range(1, len(beat_times))
    ]

    # Reverse the time list
    midi_new_time = list(reversed(midi_time))

    # Create MIDI messages
    for note, time in zip(midi_note, midi_new_time):

        # Write MIDI message and append to the MIDI track
        if note > 0:
            message_on = mido.Message(
                "note_on", note=note, velocity=velocity, time=int(round(time * 1000))
            )
            message_off = mido.Message(
                "note_off", note=note, velocity=velocity, time=int(round(time * 1000))
            )
            track.append(message_on)
            track.append(message_off)

    # Save MIDI file
    midi_file_name = os.path.join(midi_folder, file_name + ".mid")
    midi.save(midi_file_name)

    return midi_file_name


if __name__ == "__main__":

    # Sample audio file
    audio_file = "audio_sample/sample2.m4a"

    # Audio file to MIDI Conversion
    if wav_to_midi(audio_file) is None:
        print("Please provide audio file with extension of mp3, m4a or wav.")
